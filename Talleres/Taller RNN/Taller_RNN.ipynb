{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9Kui4ByqH7"
      },
      "source": [
        "# RNN - Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO8NFzPnhk4u"
      },
      "source": [
        "### Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpDNsLFfhqC1"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "np.random.seed(5)\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, SimpleRNN\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O09tnAqBhra-"
      },
      "source": [
        "### Lectura del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdIvv9YBiIVe",
        "outputId": "2232d79f-90d5-41ff-bb4c-92d3446b7430"
      },
      "source": [
        "# 1. LECTURA DEL SET DE DATOS\n",
        "# ===========================================================\n",
        "# Abre el archivo nombres_dinosaurios.txt en modo de lectura y se le asgina a la variable llamada nombre\n",
        "nombres = open('nombres_dinosaurios.txt','r').read()\n",
        "# Se ponen todas las minúsculas los nombres de los dinosaurios\n",
        "nombres = nombres.lower()\n",
        "\n",
        "# Crear  listado de caracteres que no se repiten\n",
        "alfabeto = list(set(nombres))\n",
        "''' \n",
        "\t- tam_alfabeto :  Se obtiene la cantidad de letras (Longitud de la lista alfabeto)\n",
        "\t- tam_datos :     Se obtiene la cantidad de caracteres de cada dinosausrio (Incluye repetidos)\n",
        "'''\n",
        "tam_datos, tam_alfabeto = len(nombres), len(alfabeto)\n",
        "# Imprime el número de caracteres y el número de \n",
        "print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (tam_datos, tam_alfabeto))\n",
        "\n",
        "# Conversión de caracteres a índices y viceversa\n",
        "'''\n",
        "Ordena los caracteres en orden alfábetico y a cada uno le asigna un número.\n",
        "Esto incluye saltos de linea \"\\n\".\n",
        "\t- En cara_a_ind se le asigna un número a cada elemento de alfabeto\n",
        "\t- En ind_a_cara se le asigna un elemento de alfabeto a un número.\n",
        "\n",
        "'''\n",
        "car_a_ind = { car:ind for ind,car in enumerate(sorted(alfabeto))}\n",
        "ind_a_car = { ind:car for ind,car in enumerate(sorted(alfabeto))}\n",
        "\n",
        "#Se imprimen los resultados\n",
        "print(car_a_ind)\n",
        "print(ind_a_car)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En total hay 19909 caracteres, y el diccionario tiene un tamaño de 27 caracteres.\n",
            "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fhbIxDuiTLu"
      },
      "source": [
        "### Construcción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSfWIBAYiTcl",
        "outputId": "bebef175-f494-409e-a76e-a6ef83a36f0e"
      },
      "source": [
        "# 2. MODELO\n",
        "# ===========================================================\n",
        "n_a = 25    # Número de unidades en la capa oculta , numero de neuronas \n",
        "#Entradas de nombres de dinosaurios con tamaño variable \n",
        "entrada  = Input(shape=(None,tam_alfabeto)) #Se crea una tupla con las dimensiones (0,0,27(Alfabeto)\n",
        "a0 = Input(shape=(n_a,))    #Crea una tupla con las dimensiones (0,0,25)\n",
        "\n",
        "#Generar el nuevo estado oculto usando Tanh ,return_state : a la salida retorna el nuevo estado oculto\n",
        "celda_recurrente = SimpleRNN(n_a, activation='tanh', return_state = True) #Crear el modelo de redes recurrente \n",
        "#Generar la salida o prediccion ,27 neuronas de salida (alfabeta )\n",
        "capa_salida = Dense(tam_alfabeto, activation='softmax') #Crear la capa densa , con la funcion de activacion softmax\n",
        "\n",
        "salida = [] #Crear una lista para almacenar la salida  de la prediccion \n",
        "hs, _ = celda_recurrente(entrada, initial_state=a0) #Fijar el modelo con un tamaño de 25 como entrada y 25 como salida\n",
        "salida.append(capa_salida(hs))  #Agregar la capa con el modelo al arreglo de salida\n",
        "#Agrupar los dos input, el simpleRNN y la capa densa en la variable modelo\n",
        "#2 entradas  el caracter actual y el estado oculto anterior\n",
        "modelo = Model([entrada,a0],salida)\n",
        "modelo.summary()\n",
        "\n",
        "#OPtimizador \n",
        "opt = SGD(lr=0.0005) #Se define el gradiente decendente\n",
        "modelo.compile(optimizer=opt, loss='categorical_crossentropy') #Agregar el gradiente al modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, 25),         1325        ['input_1[0][0]',                \n",
            "                                 (None, 25)]                      'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 27)           702         ['simple_rnn[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,027\n",
            "Trainable params: 2,027\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH6xSde5i1TN"
      },
      "source": [
        "### Generación del conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-da01PkNi1cO"
      },
      "source": [
        "# 3. EJEMPLOS DE ENTRENAMIENTO\n",
        "# ===========================================================\n",
        "# Whit : Determinar la configuración local que tendrá un bloque de código, lo que se conoce como \"contexto\".\n",
        "# Crear lista con ejemplos de entrenamiento y mezclarla aleatoriamente\n",
        "with open(\"nombres_dinosaurios.txt\") as f:          # como primer paso volvemos cada linea del archivo como un elemento del objeto lista\n",
        "    ejemplos = f.readlines()                        # despues se transforma a minusculas y se les agregan espacios \n",
        "ejemplos = [x.lower().strip() for x in ejemplos]    # por ultimos se mezcla su contenido sin alterarlo.\n",
        "np.random.shuffle(ejemplos)\n",
        "\n",
        "# Crear ejemplos de entrenamiento usando un generador\n",
        "def train_generator():\n",
        "    while True:\n",
        "        # Tomar un ejemplo aleatorio\n",
        "        ejemplo = ejemplos[np.random.randint(0,len(ejemplos))]\n",
        "\n",
        "        # Convertir el ejemplo a representación numérica\n",
        "        X = [None] + [car_a_ind[c] for c in ejemplo]\n",
        "\n",
        "        # Crear \"Y\", resultado de desplazar \"X\" un caracter a la derecha\n",
        "        Y = X[1:] + [car_a_ind['\\n']]\n",
        "\n",
        "        # Representar \"X\" y \"Y\" en formato one-hot            # crea una columna binaria para cada categoría, en una matriz numerica.\n",
        "        x = np.zeros((len(X),1,tam_alfabeto))\n",
        "        onehot = to_categorical(X[1:],tam_alfabeto).reshape(len(X)-1,1,tam_alfabeto)\n",
        "        x[1:,:,:] = onehot\n",
        "        y = to_categorical(Y,tam_alfabeto).reshape(len(X),tam_alfabeto)\n",
        "\n",
        "        # Activación inicial (matriz de ceros) , se actualiza a medida que se le presentan los caracteres al modelo \n",
        "        a = np.zeros((len(X), n_a))\n",
        "\n",
        "        yield [x, a], y  #mantenemos los valores en el espacio de memoria "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VTAC48gjPcW"
      },
      "source": [
        "### Entrenamiento de la red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jju09IzZjPlO",
        "outputId": "15eee966-9a9c-44b7-aaa8-abac6f7f94d1"
      },
      "source": [
        "# 4. ENTRENAMIENTO\n",
        "# ===========================================================\n",
        "BATCH_SIZE = 80\t\t\t# Número de ejemplos de entrenamiento a usar en cada iteración\n",
        "NITS = 10000\t\t\t# Número de iteraciones\n",
        "#Ciclo para iniciar las iteraciones, la cuales son 10000\n",
        "for j in range(NITS):\n",
        "    '''\n",
        "    Se inicia el entrenamiento con el modelo definidio en la sección dos\n",
        "    Por medio de la función train_generator definidia en la sección 3 se crean ejemplos de entrenamiento usando un generador+\n",
        "    steps_per_epoch  es un parámetro que representa el número de iteraciones por lotes antes de que una época\n",
        "      de entrenamiento se considere terminada.\n",
        "    verbose=0 hace referencia que no va a mostrar nada como salida\n",
        "    epochs=1 hace referencia al número de iteraciones sobre los datos proporcionados\n",
        "\t\n",
        "    '''\n",
        "    historia = modelo.fit_generator(train_generator(), steps_per_epoch=BATCH_SIZE, epochs=1, verbose=0)\n",
        "\n",
        "    # Imprimir evolución del entrenamiento cada 1000 iteraciones\n",
        "    # Támbién muestra el historial de pérdidas\n",
        "    if j%1000 == 0:\n",
        "        print('\\nIteración: %d, Error: %f' % (j, historia.history['loss'][0]) + '\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteración: 0, Error: 3.340127\n",
            "\n",
            "\n",
            "Iteración: 1000, Error: 2.398685\n",
            "\n",
            "\n",
            "Iteración: 2000, Error: 2.253265\n",
            "\n",
            "\n",
            "Iteración: 3000, Error: 2.175043\n",
            "\n",
            "\n",
            "Iteración: 4000, Error: 2.186652\n",
            "\n",
            "\n",
            "Iteración: 5000, Error: 2.171052\n",
            "\n",
            "\n",
            "Iteración: 6000, Error: 2.143520\n",
            "\n",
            "\n",
            "Iteración: 7000, Error: 2.237665\n",
            "\n",
            "\n",
            "Iteración: 8000, Error: 2.203322\n",
            "\n",
            "\n",
            "Iteración: 9000, Error: 2.175839\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuT8MqpCjn4k"
      },
      "source": [
        "### Generación de nombres usando el modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4il9OoKHWJb",
        "outputId": "6e8162d6-f9f4-4390-fdfb-0c5f0e952dce"
      },
      "source": [
        "# 5. GENERACIÓN DE NOMBRES USANDO EL MODELO ENTRENADO\n",
        "# ===========================================================\n",
        "def generar_nombre(modelo,car_a_num,tam_alfabeto,n_a):\n",
        "    # Inicializar x y a con ceros\n",
        "    x = np.zeros((1,1,tam_alfabeto,))\n",
        "    a = np.zeros((1, n_a))\n",
        "\n",
        "    # Nombre generado y caracter de fin de linea\n",
        "    nombre_generado = ''\n",
        "    fin_linea = '\\n'\n",
        "    car = -1\n",
        "\n",
        "    # Iterar sobre el modelo y generar predicción hasta tanto no se alcance\n",
        "    # \"fin_linea\" o el nombre generado llegue a los 50 caracteres\n",
        "    contador = 0\n",
        "    while (car != fin_linea and contador != 50):\n",
        "          # Generar predicción usando la celda RNN\n",
        "          #Se lleva a la capa softmax para asi generar la prediccion \n",
        "          a, _ = celda_recurrente(K.constant(x), initial_state=K.constant(a))\n",
        "          #La predccion tendra un vector de 27 elementos que representa una distribucion de probabilidad \n",
        "          y = capa_salida(a)\n",
        "          # Evalua el palor de la variable y\n",
        "          prediccion = K.eval(y)\n",
        "\n",
        "          # Escoger aleatoriamente un elemento de la predicción (el elemento con\n",
        "          # con probabilidad más alta tendrá más opciones de ser seleccionado)\n",
        "          ix = np.random.choice(list(range(tam_alfabeto)),p=prediccion.ravel())\n",
        "\n",
        "          # Convertir el elemento seleccionado a caracter y añadirlo al nombre generado\n",
        "          car = ind_a_car[ix]\n",
        "          nombre_generado += car\n",
        "\n",
        "          #se actualiza las entradas , se genera la realimentacion , la prediccion generada se volvera la entrada de la siguiente \n",
        "\n",
        "          # Crear x_(t+1) = y_t, y a_t = a_(t-1)\n",
        "          x = to_categorical(ix,tam_alfabeto).reshape(1,1,tam_alfabeto)\n",
        "          # Evalua el palor de la variable y\n",
        "          a = K.eval(a)\n",
        "\n",
        "          # Actualizar contador y continuar\n",
        "          contador += 1\n",
        "\n",
        "          # Agregar fin de línea al nombre generado en caso de tener más de 50 caracteres\n",
        "          if (contador == 50):\n",
        "            nombre_generado += '\\n'\n",
        "\n",
        "    #Imprime el nombre que se generó\n",
        "    print(nombre_generado)\n",
        "\n",
        "# Generar 100 ejemplos de nombres generados por el modelo ya entrenado\n",
        "for i in range(100):\n",
        "    generar_nombre(modelo,car_a_ind,tam_alfabeto,n_a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kushuruhocosana\n",
            "\n",
            "patuapsbalodoptrlasaurusaxadusaposaurzuseplrusauar\n",
            "\n",
            "kapostasauruchsaurosapsaususaphropezheruryptosaury\n",
            "\n",
            "aposasasausauralurzworgicatrusatarunomogdornomauro\n",
            "\n",
            "nsalelosex\n",
            "\n",
            "ramaraushus\n",
            "\n",
            "alacazerthnn\n",
            "\n",
            "ocosalosaposatostivlogruryosatosasasauralarausaurg\n",
            "\n",
            "rsanhonnklisaurusausaurausaushururachoichxtoclthao\n",
            "\n",
            "csanisauraushtachpasurosactsourausauromelleles\n",
            "\n",
            "eltels\n",
            "\n",
            "zx\n",
            "\n",
            "hima\n",
            "\n",
            "daurhuaroerhoseirmbryusushuraisadosatergatronagosa\n",
            "\n",
            "llbrainymergler\n",
            "\n",
            "eragahosanixlasucosashorolasmictata\n",
            "\n",
            "ltiuroilamertryptrhimauraushys\n",
            "\n",
            "huos\n",
            "\n",
            "megg\n",
            "\n",
            "gigaphsaytrdoercechmosasasaurees\n",
            "\n",
            "cosauros\n",
            "\n",
            "gr\n",
            "\n",
            "llltrocaprnonalrakorothipksus\n",
            "\n",
            "ng\n",
            "\n",
            "dolocephstispass\n",
            "\n",
            "amorrangodopta\n",
            "\n",
            "loctaos\n",
            "\n",
            "aces\n",
            "\n",
            "traururusys\n",
            "\n",
            "jura\n",
            "\n",
            "maururonsavosailolisprocosts\n",
            "\n",
            "sis\n",
            "\n",
            "tr\n",
            "\n",
            "athos\n",
            "\n",
            "lalosaorolaltrusapszrusa\n",
            "\n",
            "tacrcasasasaukanatecosagosanhira\n",
            "\n",
            "dorosaggyngyorhaosaborusancicushanagsosauraurasach\n",
            "\n",
            "dosps\n",
            "\n",
            "catiretosaiaslirageosatodosaveruspsa\n",
            "\n",
            "aroosapososaptitathoitylbryonarechasahuronmnelllta\n",
            "\n",
            "psausaurusasausurusasa\n",
            "\n",
            "tinoprsusausberanosachosaus\n",
            "\n",
            "hivaliazhiraarhenororaplazyswveps\n",
            "\n",
            "elophaspalatatosahusteofalusauosusostitapachsasaca\n",
            "\n",
            "gvevotranggsatasilorosawqlosasygltorelosasosachr\n",
            "\n",
            "ngalracesa\n",
            "\n",
            "rua\n",
            "\n",
            "phsinaloroshagrndrgosamosausosagisauroramarbernaur\n",
            "\n",
            "tacanoprotiphxelltrua\n",
            "\n",
            "tialkerangr\n",
            "\n",
            "baurajocosantellorusosthosaposahursasrurusklontitr\n",
            "\n",
            "bes\n",
            "\n",
            "goxingroraitatosaurodrurausscanoiobvrosaushinausau\n",
            "\n",
            "lesurusughirpas\n",
            "\n",
            "vedus\n",
            "\n",
            "ltitososatlmdrurps\n",
            "\n",
            "ms\n",
            "\n",
            "rasabruraposauraparviaralapbarusaurusaurausonobyss\n",
            "\n",
            "harurgrdrsksaurkustioprrochaerusukkhanoeralangasag\n",
            "\n",
            "passanryusauronotrigruropeslarorsaustosa\n",
            "\n",
            "domentisamoheisaur\n",
            "\n",
            "ithlonhierusochhirubaucadyoropasasatorochryusakosp\n",
            "\n",
            "bonauramosaueoposhystoshgyxtalasusaxagentrdysanaos\n",
            "\n",
            "losasisaletruosalosalellllosaci\n",
            "\n",
            "ltrauceliapraullopashuracephicpsmos\n",
            "\n",
            "omerkpsiaosanosang\n",
            "\n",
            "tocoramogrins\n",
            "\n",
            "sasapaolalosayradrapangigkelorhirausyus\n",
            "\n",
            "belaceryurausatasa\n",
            "\n",
            "kurosachdopsfylerosarusadreeryrakrnodosprtomopsani\n",
            "\n",
            "los\n",
            "\n",
            "osasas\n",
            "\n",
            "tochtosaiybroranosashicasacrsacoshugodorosmisphica\n",
            "\n",
            "ochriamasacrongomallaronanasakacelptrhalobaphacisa\n",
            "\n",
            "eposawwcosodrus\n",
            "\n",
            "cys\n",
            "\n",
            "lins\n",
            "\n",
            "doropthithasaus\n",
            "\n",
            "hheopda\n",
            "\n",
            "alasapspacosachrepesauscltoedonosasasusasosanonolo\n",
            "\n",
            "trosalgrinarururaasankusteopkeyauros\n",
            "\n",
            "any\n",
            "\n",
            "amys\n",
            "\n",
            "aasiuberangkuspatosanarauroeratr\n",
            "\n",
            "awatardophen\n",
            "\n",
            "hasaurisaurausauropochtolushyruveralosaningbbrus\n",
            "\n",
            "s\n",
            "\n",
            "thus\n",
            "\n",
            "booaestrusadroatirusaiosapasacleloraadagngosanosas\n",
            "\n",
            "lmkodridamorourausa\n",
            "\n",
            "asaus\n",
            "\n",
            "ntygosenaptryurhuspthursasdatauapos\n",
            "\n",
            "ngolosophsezhodoss\n",
            "\n",
            "azasanoxychsakransabophatosans\n",
            "\n",
            "mats\n",
            "\n",
            "zosong\n",
            "\n",
            "chs\n",
            "\n",
            "leoprsapryprsakerdrurus\n",
            "\n",
            "racastchyorurhacspenons\n",
            "\n",
            "dwmururopsshiroesaphayuronengnshielalrsusaursiaker\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}